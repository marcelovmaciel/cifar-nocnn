{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercicio - CIFAR10",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelovmaciel/cifar-nocnn/blob/master/Exercicio_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0XHqz1rGCTrB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Algoritmo:\n",
        "\n",
        "1. Importar bibliotecas basicas e dataset CIFAR10\n",
        "2. Aplicar SURF/SIFT em todas as imagens, salvando os descriptors das features das imagens\n",
        "3. Agrupar (cluster) descriptors semelhantes (para que eles podem ser identificados como um mesmo descriptor). As médias de descriptors semelhantes são usados como base de um dicionário de features.\n",
        "4. Mapear os descriptors de cada imagem para os descriptors do dicionário (Dessa forma, as imagens são transformadas em um vetor, onde cada valor é o número de ocorrências dos descriptors base do dicionário)\n",
        "5. Finalmente, treinar um classificador usando os vetores de descriptors como entrada (tendo em mente que um RF aplicado nas imagens sem pre-processamento tem acurácia de 48%)."
      ]
    },
    {
      "metadata": {
        "id": "Cpaa_s_9JvNY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nesses links, é mostrado o que está sendo almejado com esse código.\n",
        "\n",
        "https://towardsdatascience.com/bag-of-visual-words-in-a-nutshell-9ceea97ce0fb\n",
        "\n",
        "https://www.mathworks.com/help/vision/examples/image-category-classification-using-bag-of-features.html\n",
        "\n",
        "A ideia é criar um dicionário de features, um espaço vetorial, no qual as imagens possam ser analisadas em busca das caracteristicas que separam uma classe de outra.\n",
        "\n",
        "A técnica se chama \"Bag of features\", em analogia ao equivalente para textos \"Bag of Words\". Ou também \"Bag of Visual Words\" (BOVW)."
      ]
    },
    {
      "metadata": {
        "id": "BILBp4h9HFqp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Bibliotecas e Base de dados CIFAR10"
      ]
    },
    {
      "metadata": {
        "id": "fGIZ1Pgy3bVG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UwOlhcXyB2mZ",
        "colab_type": "code",
        "outputId": "76d81d86-2c25-44eb-a44e-aa8c9aee79aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/datasets/\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(images_train, labels_train), (images_test, labels_test) = cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NigtK-pMB5ZE",
        "colab_type": "code",
        "outputId": "68633ea9-fd18-40a4-bb65-da3e5c46ddfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 50000 imagens de treino de 32x32 em RGB\n",
        "# Base de testes tem 10000\n",
        "images_train.shape "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "6YtET31DCW-H",
        "colab_type": "code",
        "outputId": "ce9c277b-ba6f-4c68-e5b5-4bf991eba367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 50000 labels dos dados de treino\n",
        "labels_train.shape "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "QM845B7KHOLZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**OpenCV com pacotes patentiados**"
      ]
    },
    {
      "metadata": {
        "id": "uJmpY1zaiF_O",
        "colab_type": "code",
        "outputId": "f5b5c5e6-7efa-4bb5-8525-22b29cde40a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "cell_type": "code",
      "source": [
        "# SIFT faz parte de um modulo especial do OpenCV.\n",
        "# Precisa instalar como se fosse outra biblioteca e as versões devem ser compatíveis.\n",
        "# https://stackoverflow.com/questions/52305578/sift-cv2-xfeatures2d-sift-create-not-working-even-though-have-contrib-instal\n",
        "\n",
        "!pip install opencv-python==3.4.2.16\n",
        "!pip install opencv-contrib-python==3.4.2.16\n",
        "\n",
        "import cv2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-python==3.4.2.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/7d/5042b668a8ed41d2a80b8c172f5efcd572e3c046c75ae029407e19b7fc68/opencv_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl (25.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 25.0MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.2.16) (1.16.2)\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 3.4.5.20\n",
            "    Uninstalling opencv-python-3.4.5.20:\n",
            "      Successfully uninstalled opencv-python-3.4.5.20\n",
            "Successfully installed opencv-python-3.4.2.16\n",
            "Collecting opencv-contrib-python==3.4.2.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/f1/66330f4042c4fb3b2d77a159db8e8916d9cdecc29bc8c1f56bc7f8a9bec9/opencv_contrib_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl (30.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 30.6MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.16) (1.16.2)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Found existing installation: opencv-contrib-python 3.4.3.18\n",
            "    Uninstalling opencv-contrib-python-3.4.3.18:\n",
            "      Successfully uninstalled opencv-contrib-python-3.4.3.18\n",
            "Successfully installed opencv-contrib-python-3.4.2.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JTtuyK2nHZpx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. SIFT feature extraction"
      ]
    },
    {
      "metadata": {
        "id": "xFl8btpfaqqQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Links:\n",
        "# https://stackoverflow.com/questions/29133085/what-are-keypoints-in-image-processing\n",
        "# https://docs.opencv.org/3.4.0/df/dd2/tutorial_py_surf_intro.html\n",
        "# https://www.pyimagesearch.com/2015/07/16/where-did-sift-and-surf-go-in-opencv-3/\n",
        "\n",
        "# Are the keypoint objects useful at all for image classification?\n",
        "# kp, des = surf.detectAndCompute(img,None)\n",
        "\n",
        "# Tried to solve the problem with list comprehension.\n",
        "# Images have different number of features. Have to make results have same size.\n",
        "# Could not get it to work. Maybe it was because of the NoneType error, idk.\n",
        "\n",
        "# sift = cv2.xfeatures2d.SIFT_create(30)\n",
        "# features = [sift.detectAndCompute(image, None)[1] for image in x_train]\n",
        "# for i in range(50000):\n",
        "#     features2[i][0:np.size(features[i])] += np.flatten(features[i])\n",
        "\n",
        "# Theoretically, SURF is better than SIFT (they are both functions for extracting features),\n",
        "# but SURF is giving me almost zero features when applied to the images, while\n",
        "# SIFT gives an average of around 13"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SFT6I0gB-6Vs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Old code. Ignore this.\n",
        "\n",
        "# Code for extracting descriptors and, since the number of features per image is different,\n",
        "# pad the descriptor vector of the images with zeros to make them have the same size\n",
        "# and create a matrix of same sized vectors to use as input for the classifier\n",
        "\n",
        "# features = np.zeros((50000, 4500))\n",
        "# totalfeatures = 0\n",
        "# for i in range(50000):\n",
        "#     sift = cv2.xfeatures2d.SIFT_create(500)\n",
        "#     # gray = cv2.cvtColor(x_train[i], cv2.COLOR_BGR2GRAY)\n",
        "#     des = sift.detectAndCompute(x_train[i], None)[1]\n",
        "#     if des is not None: # Some images have no features and return a NoneType\n",
        "#         totalfeatures += len(des)\n",
        "#         des = des.flatten()\n",
        "#         features[i][0:len(des)] = des\n",
        "        \n",
        "# features2 = np.zeros((10000, 4500))\n",
        "# for i in range(10000):\n",
        "#     sift = cv2.xfeatures2d.SIFT_create(500)\n",
        "#     # gray = cv2.cvtColor(x_test[i], cv2.COLOR_BGR2GRAY)\n",
        "#     des = sift.detectAndCompute(x_test[i], None)[1]\n",
        "#     if des is not None: # Some images have no features and return a NoneType\n",
        "#         des = des.flatten()\n",
        "#         features2[i][0:len(des)] = des        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dVrXemeKMuZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extracting descriptors from the images and creating a list of descriptor vectors\n",
        "\n",
        "# Descriptors of the Images\n",
        "# Remember some images dont have any descriptors.\n",
        "# These will have a None at its position in the descriptor list\n",
        "maxfeaturesperimage = 500\n",
        "\n",
        "sift = cv2.xfeatures2d.SIFT_create( maxfeaturesperimage )\n",
        "descriptors_train = [sift.detectAndCompute(image, None)[1] for image in images_train]\n",
        "descriptors_test  = [sift.detectAndCompute(image, None)[1] for image in images_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o3WbA6VIYDcV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Dicionário de features"
      ]
    },
    {
      "metadata": {
        "id": "naXp6_35fq_s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "indexesNotNone = [(item is not None) for item in descriptors_train] # list of bool for not-NoneType entries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wKApZm1_hnr2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "indexesNotNone = np.array(indexesNotNone).nonzero()[0] # converting to list of integer indexes. (nonzero() returns a tuple)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hL9eBNnbi_4Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "descriptors_train = np.array(descriptors_train) # Lists do not accept list of indexes. Must convert to np.array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DkDB4pjbiEpc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "descriptor_list = np.concatenate(descriptors_train[indexesNotNone])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pIVeBDKcaUz1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZndAjBOMYKo3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feature_dict = KMeans(n_clusters= 500, verbose= True, max_iter= 40, n_jobs= -1)\n",
        "feature_dict.fit(descriptor_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jN1sSiJjntuD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Mapeamento dos descriptors usando o dicionário"
      ]
    },
    {
      "metadata": {
        "id": "rsIKQk87uWYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_train = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4SdbuAy7aSst",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_train = []\n",
        "for image in images:\n",
        "      image = gray(image)\n",
        "      keypoint, descriptor = features(image, extractor)\n",
        "      if (descriptor is not None):\n",
        "          histogram = build_histogram(descriptor, kmeans)\n",
        "          preprocessed_image.append(histogram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W0HvoE8WuVZy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_histogram(descriptor_list, cluster_alg):\n",
        "    histogram = np.zeros(len(cluster_alg.cluster_centers_))\n",
        "    cluster_result =  cluster_alg.predict(descriptor_list)\n",
        "    for i in cluster_result:\n",
        "        histogram[i] += 1.0\n",
        "    return histogram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rJ4qa6j7aUvP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Rascunho"
      ]
    },
    {
      "metadata": {
        "id": "rr7ipmG53EUe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "np.fft2(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xXEp7Qle3WBX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "img = Image.open('image.png').convert('LA')\n",
        "img.save('greyscale.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jmqpO3Lq3trl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img = Image.fromarray(x_train[7])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VrEalhLT4w01",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img = img.convert('LA')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xxJbuBIG31U2",
        "colab_type": "code",
        "outputId": "bf17f077-8361-4441-fd93-f1adb0c71dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "cell_type": "code",
      "source": [
        "img.resize((200,200))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAQAAAAHUWYVAAAKNklEQVR4nO2dS49VVRSET9MbQRS9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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=LA size=200x200 at 0x7FE245A0AFD0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "YuMQXlpq4HaA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X84ttb5caXi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "272d7743-1a7d-4012-dd21-97581ca7fc5d"
      },
      "cell_type": "code",
      "source": [
        "Image.fromarray(gray)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADTUlEQVR4nAXB224cNRgAYB9+23PY\nndlDdtMkTREE2gYkAlQqvUD0jhfgBZF4AiTEEyCVG2ivEBCSVG2STbLL7G5mxh7b89t8H/12zcRk\nVILiaxyh7ZKoy2gZH+TSUm4j/LlSYydcYNYg5z1XBjWz0vU5A2q9AC7H81lGtaUp9qNeobRBSdkG\nQrO2p/dA870Eq9hBKbd8WBtLcosKmRehDixoUCIfIqEMIVq+7LXPXaRKJ6TzpNUdQsElzXtivQvI\nu9ijqalZ1fsTVTXN/YLBlGchRk2LbFN0N55ksYq0OFm7TFLxYF7DoBOqC+MYXL6+qkP6cv7HGdL1\nhstEEjxcw3TFjKOe+BFetxAl3ezUVfc3koQVwXVT2Mn5tgkRBuzMCJnBeSjL4Luu7wlj4AIwQVSk\nLGarauzzDx1sUR19dHpGfRQyEAq2iw1y3T50o7n7FLcjtdc8LZNqm1AMnkaIGBNZXfPb5ejF4nB2\nVxJ+S25vZWEFjZRFKHnrN+8bWacPDxp5srCoDzAvJ6slczTREjY2Ml4P8u2DL9dXH9efhDau3Diq\n6pdrQQLxQDWNwbc4fPnZD4k/P5r4iptmf69KKfEh9Cz2SGwsiq9etO4gzl1z7/ji13e4kQ/mszIa\nQJcLv5scfvPkx/3j3Vxvr29cPrrY07btiZxo4LXN6Pj262eiGT6Rr832CtWjxyLp7SUSXu5CpxKK\n6fffzc5IfdH+lJjZ4DIeHJPad8QFPQEM6Gn+TLy5sutT2vNyfOPrt6LhWUxHokGIXmIY/fz7fisH\nXMzqdOnT9s2pAzoTihRPIQKn4BdLR8d7/TVhnqSxpybWtIzodmeMJzHdcTlstrocnAjC2sBFf/XP\nRTeQ2hUdA0vBsrTM55V9FJ9/IVpDydU7nU/71k9n/0L53hECJWtEeLW6pgqy1vj0ZEji2mTH09ew\n29w1JG89XenOF0sdZ7hRBfdgPD/cXVQwZMNsY4Ai3ifG+Z7Ug8JUOSMSxVH32znIPPFcwyC0Sorg\nI3EW5NqVDEjVtq86sEKhMq4zLpOOM8lSHlSxjuP+8q/xnBaw/C+HZGhaXlNEpBQChsZAg/XbTTf9\nwEIyVXE4jlbXLhI0EqwOVLiBSuHk88fP7/4HQPgCoAZAGEEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=32x32 at 0x7FE292A332E8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "2nuCfM5croEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ca64aa3-123a-4544-d74d-6fb6e9d205cb"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "ZvmGGjt4sC__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "d79dc30c-655c-4a50-de1e-285a53cb0e08"
      },
      "cell_type": "code",
      "source": [
        "np.concatenate(x_train[0].reshape(1, -1), features[0][1])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-c0e589e720ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "1d07Las2sjDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "26edbb97-cf6e-468d-c61f-187a587af81a"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<KeyPoint 0x7fe291f8b600>,\n",
              "  <KeyPoint 0x7fe291f8b630>,\n",
              "  <KeyPoint 0x7fe291f8b660>,\n",
              "  <KeyPoint 0x7fe291f8b690>,\n",
              "  <KeyPoint 0x7fe291f8b840>,\n",
              "  <KeyPoint 0x7fe291f8b7b0>,\n",
              "  <KeyPoint 0x7fe291f8b960>,\n",
              "  <KeyPoint 0x7fe291f8b990>,\n",
              "  <KeyPoint 0x7fe291f8b9c0>,\n",
              "  <KeyPoint 0x7fe291f8b9f0>,\n",
              "  <KeyPoint 0x7fe291f8ba20>,\n",
              "  <KeyPoint 0x7fe291f8ba50>,\n",
              "  <KeyPoint 0x7fe291f8ba80>,\n",
              "  <KeyPoint 0x7fe291f8bab0>,\n",
              "  <KeyPoint 0x7fe291f8bae0>,\n",
              "  <KeyPoint 0x7fe291f8bb10>,\n",
              "  <KeyPoint 0x7fe291f8bb40>,\n",
              "  <KeyPoint 0x7fe291f8bb70>],\n",
              " array([[ 30., 101.,  14., ...,   0.,   0.,  45.],\n",
              "        [  0.,   0.,   0., ...,  52.,  17.,   7.],\n",
              "        [  2.,   5.,   9., ...,  32.,  17.,  36.],\n",
              "        ...,\n",
              "        [  0.,   0.,   0., ...,  34.,   4.,   9.],\n",
              "        [ 72.,  36.,  10., ...,   4.,   1.,   0.],\n",
              "        [  2.,   0.,   0., ...,   1.,  47., 153.]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "QCjwAudGsmOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.arange(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "glYz8K1Iki9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f94b91a4-4363-4dd5-9921-ce9e975f688c"
      },
      "cell_type": "code",
      "source": [
        "type(descriptors_train)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "metadata": {
        "id": "4-xVzMpxkleI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ind = np.array([0,1,2,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j8Jit9FqlU9g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}